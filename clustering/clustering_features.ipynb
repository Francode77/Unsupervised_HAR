{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the dataframe with the extracted features\n",
    "\n",
    "This will obtain all extracted features from files in directory /processed/ts/ in one dataframe\n",
    "\n",
    "init value determines if we will start with reading the dataframe<br>\n",
    "'init value=1' read dataframe<br>\n",
    "'init value=0' use the one in memory<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=1 # Whether to read in the dataframe\n",
    "\n",
    "if init==0:\n",
    "    datapath=os.path.join('../data/processed/unlabeled/ts/')\n",
    "    file_nr=int(0)\n",
    "    total_files=len(listdir(datapath))\n",
    "    nr_of_frames=int(0)\n",
    "    df_full=pd.DataFrame()\n",
    "    for file in listdir(datapath):\n",
    "        if '.csv' in file:\n",
    "            df=pd.read_csv(os.path.join(datapath,file))\n",
    "            df['file']=file\n",
    "            df['file_nr']=file_nr+1\n",
    "            frame_index=df['frame'].to_numpy()\n",
    "            frame_index+=nr_of_frames\n",
    "            df['frame']=frame_index\n",
    "            \n",
    "            nr_of_frames+=len(df[df['file']==file_nr+1])\n",
    "            file_nr+=1 # Counter\n",
    "        df_full=pd.concat([df_full,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this full dataframe for training\n",
    "\n",
    "df_full.reset_index(drop=True,inplace=True)\n",
    "df_train=df_full\n",
    "\n",
    "df_train_features = df_train.drop(['file_nr','file','frame','Unnamed: 0'], axis=1)\n",
    "df_train_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSFRESH extracts all these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_patterns=[...]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We select only a few of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_features=[\n",
    "    'variance_larger_than_standard_deviation',\n",
    " 'median',\n",
    " 'mean',\n",
    " 'sum_values',\n",
    " 'abs_energy',\n",
    " 'acc_x_n_length',\n",
    " 'standard_deviation',\n",
    " 'mean_change',\n",
    " 'variation_coefficient',\n",
    " 'variance',   \n",
    " 'maximum',\n",
    " 'absolute_maximum',\n",
    " 'minimum',  \n",
    " 'linear_trend__attr_\"slope\"',\n",
    " 'agg_linear_trend__attr_\"slope\"__chunk_len_50__f_agg_\"mean\"' \n",
    " ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the signals we will use for clustering\n",
    "\n",
    "And here we also drop the columns of the unused features from the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_list_of_signals=['acc_x_n','acc_y_n','acc_z_n','acc_x_r','acc_y_r','acc_z_r','gyr_x_n','gyr_y_n','gyr_z_n','gyr_x_r','gyr_y_r','gyr_z_r','alpha_r','beta_r']\n",
    "list_of_signals=['acc_x_n','acc_y_n','acc_z_n','acc_x_r','gyr_y_n','alpha_r','beta_r']\n",
    "list_of_signals=complete_list_of_signals\n",
    "drop_these_columns=[]\n",
    "for column in df_train_features.columns: \n",
    "    for pattern in list_of_patterns:\n",
    "        if pattern in column:\n",
    "            if pattern not in list_of_features:\n",
    "                drop_these_columns.append(column)\n",
    "\n",
    "df_train_features.drop(drop_these_columns,inplace=True,axis=1)\n",
    "\n",
    "drop_these_columns=[]\n",
    "for column in df_train_features.columns: \n",
    "    for signal in complete_list_of_signals:\n",
    "        if signal in column:\n",
    "            if signal not in list_of_signals:\n",
    "                drop_these_columns.append(column)\n",
    "\n",
    "\n",
    "df_train_features.drop(drop_these_columns,inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the features for use in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "df_train_features = pd.DataFrame(ss.fit_transform(df_train_features),columns = df_train_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the remaining features\n",
    "df_train_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels = df_train['frame']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction\n",
    "\n",
    "Determine how many dimensions will be used for the clusterng model, by defining n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA method from sklearn\n",
    " \n",
    "pca_columns=[]\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "for i in range(0,n_components):\n",
    "    pca_columns.append(f'PCA{i+1}')\n",
    "\n",
    "principal_components = pca.fit_transform(df_train_features)\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=pca_columns)\n",
    "#pca_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine ideal number of clusters (Elbow method)\n",
    "\n",
    "Determine with the elbow method how many clusters would be ideal for this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_k_values = range(3, 25)\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "\n",
    "for k in possible_k_values:\n",
    "    k_means = KMeans(n_clusters=k)\n",
    "    k_means = k_means.fit(pca_df)\n",
    "\n",
    "    sum_of_squared_distances.append(k_means.inertia_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "plt.plot(possible_k_values, sum_of_squared_distances, 'rx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "\n",
    "plt.title('Elbow plot for optimal number of clusters')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the desired number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=n_clusters, max_iter=1).fit(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_kmeans= pd.concat([pca_df,pd.DataFrame({'cluster':model.labels_})],axis=1)\n",
    "#visualization_kmeans.sample(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA1 vs PCA2 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "palette= sns.color_palette()\n",
    "ax=sns.scatterplot(x=\"PCA1\",y=\"PCA2\",hue=\"cluster\",data=visualization_kmeans[['PCA1','PCA2','cluster']], palette=palette)\n",
    "plt.title(\"Clustering using K-Means Algorithm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_frame_kmeans= pd.concat([df_train_labels,visualization_kmeans],axis=1) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frames distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "palette= sns.color_palette()\n",
    "ax=sns.scatterplot(x=\"cluster\",y=\"frame\",data=cluster_frame_kmeans, palette=palette)\n",
    "plt.title(\"Frames per cluster using K-Means Algorithm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(model.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "palette= sns.color_palette()\n",
    "ax=sns.scatterplot(x=\"PCA1\",y=\"PCA2\",hue=\"frame\",data=cluster_frame_kmeans, palette=palette, legend=False)\n",
    "plt.title(\"FRAMES distribution. PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = metrics.silhouette_score(pca_df, model.labels_)  \n",
    "print(f'Parameter: {n_clusters} clusters',  'Score: ', ss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Necessary functions to get frame date from the used files and plot the validation frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from a frame\n",
    "\n",
    "def get_frame(df):\n",
    "\n",
    "    acc_x_n=np.array(df['acc_x_n'])\n",
    "    acc_y_n=np.array(df['acc_y_n'])\n",
    "    acc_z_n=np.array(df['acc_z_n'])\n",
    "    gyr_x_n=np.array(df['gyr_x_n'])\n",
    "    gyr_y_n=np.array(df['gyr_y_n'])\n",
    "    gyr_z_n=np.array(df['gyr_z_n'])\n",
    "\n",
    "    alpha_r=np.array(df['alpha_r'])\n",
    "    beta_r = np.array(df['beta_r'])\n",
    "\n",
    "    return acc_x_n,acc_y_n,acc_z_n,gyr_x_n,gyr_y_n,gyr_z_n,alpha_r,beta_r\n",
    "\n",
    "\n",
    "# Function to plot a graph of a frame\n",
    "def plot_frame(acc_x_n,acc_y_n,acc_z_n,gyr_x_n,gyr_y_n,gyr_z_n,alpha_r,beta_r,cluster,i):\n",
    "    fig,ax=plt.subplots(figsize=(16, 4))\n",
    "\n",
    "    plt.title(f'Cluster {cluster} validation: frame {i+1}')\n",
    "    ax.set_xlim(0,500)\n",
    "    axb=ax.twinx()\n",
    "    ax.plot(acc_x_n,color='tab:red',linewidth=.9 , label ='acc (x_n)', alpha=0.4)\n",
    "    ax.plot(acc_y_n,color='tab:orange',linewidth=.9 , label ='acc (y_n)', alpha=0.4)\n",
    "    ax.plot(acc_z_n,color='tab:cyan',linewidth=.9 , label ='acc (z_n)' , alpha=0.4)\n",
    "\n",
    "    ax.plot(gyr_x_n,color='tab:red',linewidth=.9 , label ='gyr (x_n)', linestyle=':', alpha=0.66)\n",
    "    ax.plot(gyr_y_n,color='tab:orange',linewidth=.9 , label ='gyr (y_n)', linestyle=':', alpha=0.66)\n",
    "    ax.plot(gyr_z_n,color='tab:cyan',linewidth=.9 , label ='gyr (z_n)' , linestyle=':', alpha=0.66)\n",
    "\n",
    "    axb.plot(alpha_r,color='tab:green',linewidth=1.6 , label ='alpha_r')\n",
    "    axb.plot(beta_r,color='tab:blue',linewidth=1.6 , label ='beta_r')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(0, 1))\n",
    "    axb.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to plot graphs for frames in a certain cluster\n",
    "\n",
    "def validate(validate_cluster,nr_frames):\n",
    " \n",
    "    for i in range(nr_frames): \n",
    "        target_frames=cluster_frame_kmeans.index[cluster_frame_kmeans.cluster==validate_cluster]\n",
    "\n",
    "        cluster_frame=i\n",
    "        target_file=df_train[df_train.index==target_frames[cluster_frame]]['file'].values\n",
    "\n",
    "        target_file=str(target_file[0])\n",
    "        target_file=re.sub('ts_feat_','frames_',target_file)\n",
    "        df_target_file=pd.read_csv(f'../data/processed/unlabeled/frames/{target_file}')\n",
    "\n",
    "        df_target_frame=df_target_file[df_target_file['frame']==cluster_frame]\n",
    "\n",
    "        df_target_frame\n",
    "\n",
    "        acc_x_n,acc_y_n,acc_z_n,gyr_x_n,gyr_y_n,gyr_z_n,alpha_r,beta_r=get_frame(df_target_frame)\n",
    "        plot_frame(acc_x_n,acc_y_n,acc_z_n,gyr_x_n,gyr_y_n,gyr_z_n,alpha_r,beta_r,validate_cluster,cluster_frame)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate on cluster number with (n) number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(4,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spinewise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5a0d97e2822d37232ba0d836d173d7255214fc6520b243ce4404dfaf902a9995"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
